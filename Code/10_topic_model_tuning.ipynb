{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IGsdeIqd7xJ",
    "tags": []
   },
   "source": [
    "# Topic model hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiexnvtGd1xt",
    "outputId": "6b9e147a-fb0a-430c-d548-3fc17de395b5"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis\n",
    "!pip3 install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V45B4I2Ad513",
    "outputId": "bc05a741-d816-4377-9f80-9ccb9d29e877"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from itertools import product\n",
    "import pickle5 as pickle\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#For plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNyOJNA8eGE_",
    "outputId": "0c6e6c09-4ffd-441c-cd4e-5847c8f4462e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjyJKBzKeHPq"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/paragraph_df.pkl', \"rb\") as fh:\n",
    "    paragraph_df = pickle.load(fh)\n",
    "paragraph_df = pd.DataFrame(paragraph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42fxX4wwR2Ju"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/report_details_df.pkl', \"rb\") as fh:\n",
    "    report_details_df = pickle.load(fh)\n",
    "report_details_df = pd.DataFrame(report_details_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eI3XpGeeMBO",
    "outputId": "4d439dd4-751e-4a76-9c71-0cb83ea9327e"
   },
   "outputs": [],
   "source": [
    "sc_only_para_df = paragraph_df[paragraph_df['Supply_Chain']=='Yes']\n",
    "print(len(sc_only_para_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtDxzbISeVmJ"
   },
   "source": [
    "## Model & variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMU3JmE7eSNw"
   },
   "outputs": [],
   "source": [
    "# Stop words\n",
    "stop_words = stopwords.words('english')\n",
    "additional_stop_words = ['report', 'annualreport','esg','sustainability',\n",
    "                         'sustainable','also','business','group','company','year'] \n",
    "sc_keywords = ['supplier', 'suppliers', 'supply', 'chain', 'chains', \n",
    "               'procurement', 'vendor', 'vendors', 'sourcing']\n",
    "\n",
    "stop_words += additional_stop_words\n",
    "stop_words += sc_keywords\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Y0rQys8ebDE"
   },
   "outputs": [],
   "source": [
    "# Limit to nouns, adjectives, and adverbs (???-check whether I want to keep this)\n",
    "def paragraphs_to_words(paragraphs):\n",
    "    for paragraph in paragraphs:\n",
    "        # note: deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(paragraph), deacc=True))\n",
    "\n",
    "def pos_and_location_filter(text):\n",
    "    doc = nlp(text)\n",
    "    included_tags = [\"NOUN\",\"ADJ\",\"ADV\"]\n",
    "    ents = [e.text for e in doc.ents if e.label_ in ['GPE','LOC','ORG']]\n",
    "    filtered_text = [item.text for item in doc if (not item.text in ents) and (item.pos_ in included_tags)]\n",
    "    return filtered_text\n",
    "        \n",
    "def text_preprocessing(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('[,\\.!?]', '', text) # remove punctuation\n",
    "    text = ''.join(i for i in text if not i.isdigit()) # remove numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text) # removes non-letter characters\n",
    "    \n",
    "    text = text.lower()\n",
    "    text_list = pos_and_location_filter(text)\n",
    "    text_list = [w for w in text_list if w not in stop_words]\n",
    "    text_list = [lemmatizer.lemmatize(word) for word in text_list]\n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeHdLvtkeeMS"
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mTKQ3U8JedfW",
    "outputId": "52043626-7c08-415d-bae7-b23f16bc4a1a"
   },
   "outputs": [],
   "source": [
    "sc_only_para_df['Processed_Text'] = sc_only_para_df['Paragraph'].map(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tQtXC0eXef9I"
   },
   "outputs": [],
   "source": [
    "def create_dict_texts_corpus(list_of_paragraphs):\n",
    "    texts = list(paragraphs_to_words(list_of_paragraphs))\n",
    "\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(texts, min_count=5, threshold=100)\n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    # Trigram texts\n",
    "    texts_w_trigrams = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "    id2word = corpora.Dictionary(texts_w_trigrams)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts_w_trigrams]\n",
    "    \n",
    "    return bigram_mod, trigram_mod, texts_w_trigrams, id2word, corpus, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Nq81Me4jehom",
    "outputId": "c5cf2927-959b-472c-c82a-6c9118be2f13"
   },
   "outputs": [],
   "source": [
    "# All docs\n",
    "total_list_of_paragraphs = sc_only_para_df['Processed_Text'].values.tolist()\n",
    "total_bigram_mod, total_trigram_mod, total_texts_w_trigrams, total_id2word, total_corpus, total_texts = create_dict_texts_corpus(total_list_of_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psbcJGVqenGF"
   },
   "source": [
    "## Pre-topic model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nZxcdmOEekog",
    "outputId": "2ec9ed32-3ce9-4762-c9bf-f0353a7683ed"
   },
   "outputs": [],
   "source": [
    "unigram_counter = Counter([word for doc in total_texts for word in doc])\n",
    "top_30_uni = unigram_counter.most_common(30)\n",
    "\n",
    "bigram_counter = Counter([word for doc in total_texts for word in total_bigram_mod[doc] if '_' in word])\n",
    "top_30_bi = bigram_counter.most_common(30)\n",
    "\n",
    "trigram_counter = Counter([word for doc in total_texts_w_trigrams for word in doc if word.count('_') == 2])\n",
    "top_30_tri = trigram_counter.most_common(30)\n",
    "\n",
    "top_words_df = pd.DataFrame({'Unigrams':top_30_uni, 'Bigrams':top_30_bi, 'Trigrams':top_30_tri})\n",
    "display(top_words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIAHlT9U1ogq"
   },
   "source": [
    "## Get best topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lVAAf1Iuep22",
    "outputId": "a8ff6873-834b-4762-df34-a03805a854d1"
   },
   "outputs": [],
   "source": [
    "def topic_model_grid_search(dictionary, corpus, texts, num_topics_range):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence, perplexity for various numbers of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    num_topics_range : List of topic counts to test\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict with LDA topic models' coherence and perplexity values\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for num_topics in tqdm(num_topics_range):\n",
    "        results[num_topics] = {}\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=num_topics, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=1000,\n",
    "                                            passes=10)\n",
    "        perplexity = model.log_perplexity(corpus)\n",
    "        results[num_topics]['perplexity'] = perplexity\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        results[num_topics]['coherence'] = coherencemodel.get_coherence()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Num topics\n",
    "num_topics_range = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 40, 80, 100, 120, 140, 160, 180, 200]\n",
    "\n",
    "results = topic_model_grid_search(dictionary=total_id2word, \n",
    "                                  corpus=total_corpus, \n",
    "                                  texts=total_texts_w_trigrams, \n",
    "                                  num_topics_range=num_topics_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PknJ2FnhELxH",
    "outputId": "6d35b717-8a5a-49c4-a560-dabd421168e4"
   },
   "outputs": [],
   "source": [
    "# Show graph\n",
    "topics = num_topics_range\n",
    "coherences = [results[t]['coherence'] for t in topics]\n",
    "plt.plot(topics, coherences, label='Coherence')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0Jq-rcDjS--Y"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/topic_model_results.txt\", \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "name": "Topic modelling colab 21-6-22.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
