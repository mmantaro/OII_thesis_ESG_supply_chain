{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095f698c-c640-428e-928b-9cd1772c61d0",
   "metadata": {
    "id": "095f698c-c640-428e-928b-9cd1772c61d0"
   },
   "source": [
    "## Fine-tuning BERT base and ESG-BERT models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18948a-f751-4fb8-8158-13a605802cd0",
   "metadata": {},
   "source": [
    "Note: This file was run with Google Colab Pro Plus using high-RAM and GPU. It therefore requires installing the relevant packages and connecting to MyDrive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181f3c3-28ce-47d5-ae39-24d99be3fa9e",
   "metadata": {
    "id": "c181f3c3-28ce-47d5-ae39-24d99be3fa9e"
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jxLdn69Lip0-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxLdn69Lip0-",
    "outputId": "ba678fa9-ef92-4639-a318-cd6d0f972a11"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip3 install pickle5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c798965-68fb-4c41-ad9f-6f90010fdfc1",
   "metadata": {
    "id": "2c798965-68fb-4c41-ad9f-6f90010fdfc1"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48804185-1f9b-41f4-a4bf-ea0d12a9d38c",
   "metadata": {
    "id": "48804185-1f9b-41f4-a4bf-ea0d12a9d38c"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle5 as pickle\n",
    "from collections import defaultdict, Counter\n",
    "from string import punctuation\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.util import bigrams\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PSE-qAlKiE6D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSE-qAlKiE6D",
    "outputId": "6801d597-2273-489d-c10d-b92f4e7f3121"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1uplOU7aYvoP",
   "metadata": {
    "id": "1uplOU7aYvoP"
   },
   "source": [
    "### Ensure reproducibility by setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kkofyB8zYuXT",
   "metadata": {
    "id": "kkofyB8zYuXT"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f518dc8-6c68-4a60-9cde-d04d8d1a12a0",
   "metadata": {
    "id": "1f518dc8-6c68-4a60-9cde-d04d8d1a12a0"
   },
   "source": [
    "### Get variables & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafee975-a0fd-48df-af5e-d7da51ac3a15",
   "metadata": {
    "id": "fafee975-a0fd-48df-af5e-d7da51ac3a15"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/train.pkl', \"rb\") as fh:\n",
    "    train_data = pickle.load(fh)\n",
    "train = pd.DataFrame(train_data)\n",
    "\n",
    "with open('/content/drive/MyDrive/val.pkl', \"rb\") as fh:\n",
    "    val_data = pickle.load(fh)\n",
    "val = pd.DataFrame(val_data)\n",
    "\n",
    "with open('/content/drive/MyDrive/test.pkl', \"rb\") as fh:\n",
    "    test_data = pickle.load(fh)\n",
    "test = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YGDfaVobohLq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGDfaVobohLq",
    "outputId": "05f3beef-6e9c-4d73-81b3-e649f088c804"
   },
   "outputs": [],
   "source": [
    "def get_augmented_dataset(df):\n",
    "    translated_indices = data_for_augmentation.index.to_list() #translated indices\n",
    "    market_indices = df.index.to_list() #indices in original df\n",
    "    indices = list(set(translated_indices) & set(market_indices)) # only check indices in both dfs\n",
    "    translated_set = data_for_augmentation.loc[indices]\n",
    "    augmented_dataset = shuffle(pd.concat([df, translated_set]), random_state=42)\n",
    "    return augmented_dataset\n",
    "\n",
    "# Get translated paragraphs\n",
    "translated_data = pd.read_excel('/content/drive/MyDrive/Back translation with GT.xlsx')\n",
    "data_for_augmentation = translated_data[translated_data['Exact match']=='No']\n",
    "data_for_augmentation.rename(columns={'Back-translation':'Paragraph'}, inplace=True)\n",
    "data_for_augmentation.drop(columns=['Original Paragraph','Exact match'], inplace=True)\n",
    "data_for_augmentation.set_index('Index',inplace=True)\n",
    "\n",
    "# Create augmented train dataset\n",
    "augmented_train = get_augmented_dataset(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bee8d-1f17-45e0-8b03-4edf5fff4d70",
   "metadata": {
    "id": "dd1bee8d-1f17-45e0-8b03-4edf5fff4d70"
   },
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9997e063-e9bd-489b-8393-6c1abd420040",
   "metadata": {
    "id": "9997e063-e9bd-489b-8393-6c1abd420040"
   },
   "outputs": [],
   "source": [
    "# Define function to clean text\n",
    "def clean(text):\n",
    "    return [w.strip(punctuation) for w in text.strip().split() if w.strip(punctuation) != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec614c66-8630-4459-b0ec-504dbcd7cbeb",
   "metadata": {
    "id": "ec614c66-8630-4459-b0ec-504dbcd7cbeb"
   },
   "outputs": [],
   "source": [
    "train['Paragraph'] = train['Paragraph'].apply(clean)\n",
    "val['Paragraph'] = val['Paragraph'].apply(clean)\n",
    "test['Paragraph'] = test['Paragraph'].apply(clean)\n",
    "augmented_train['Paragraph'] = augmented_train['Paragraph'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe3ff1-bb9f-4da3-bfa3-910e5bef243b",
   "metadata": {
    "id": "dbfe3ff1-bb9f-4da3-bfa3-910e5bef243b"
   },
   "source": [
    "### Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c54f1-6f4b-4099-884b-b6319e4b3365",
   "metadata": {
    "id": "b08c54f1-6f4b-4099-884b-b6319e4b3365"
   },
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class BERTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, label_col, hf_path):\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tok = BertTokenizer.from_pretrained(hf_path)\n",
    "        \n",
    "        # Truncate and encode paragraphs\n",
    "        self.paragraphs = list(data['Paragraph'].apply(self.tok.encode, max_length=512, truncation=True))\n",
    "        \n",
    "        # Store labels\n",
    "        self.labels = list(data[label_col])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paragraph = self.paragraphs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return paragraph, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf0feb-b470-4c04-b3eb-b4d22776a25f",
   "metadata": {
    "id": "5faf0feb-b470-4c04-b3eb-b4d22776a25f"
   },
   "outputs": [],
   "source": [
    "# Define BERT classifier\n",
    "class BERTClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hf_path, dropout_rate=0.2):\n",
    "        \n",
    "        # Define network layers\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(hf_path)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        \n",
    "        # Define dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, paragraphs, masks):\n",
    "        \n",
    "        # Define flow of tensors through network\n",
    "        output_bert = self.bert(paragraphs, attention_mask=masks)[0].mean(axis=1)\n",
    "        return self.linear(self.dropout(output_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eKsaQMfrDiJJ",
   "metadata": {
    "id": "eKsaQMfrDiJJ"
   },
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec19dc-c2f1-467b-b2bd-b9752569625a",
   "metadata": {
    "id": "f6ec19dc-c2f1-467b-b2bd-b9752569625a"
   },
   "outputs": [],
   "source": [
    "# Define collate function\n",
    "def bert_collate(batch):\n",
    "    \n",
    "    # Store batch size\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # Separate paragraphs and labels\n",
    "    paragraphs = [p for p, _ in batch]\n",
    "    labels = torch.tensor([l for _, l in batch]).long()\n",
    "    \n",
    "    # Store length of longest paragraphs in batch\n",
    "    max_len = max(len(p) for p in paragraphs)\n",
    "    \n",
    "    # Create padded paragraph and attention mask tensors (the latter to avoid performing attention on padding token indices)\n",
    "    paragraphs_pad = torch.zeros((batch_size, max_len)).long()\n",
    "    masks_pad = torch.zeros((batch_size, max_len)).long()\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        paragraphs_pad[i, :len(p)] = torch.tensor(p)\n",
    "        masks_pad[i, :len(p)] = 1\n",
    "    \n",
    "    return paragraphs_pad, masks_pad, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vbvDI0CLWTA5",
   "metadata": {
    "id": "vbvDI0CLWTA5"
   },
   "outputs": [],
   "source": [
    "def bert_finetuning(hf_path, train, val, test, col_name, lr=1e-5, epochs=20, \n",
    "                    dropout_rate=.2, validation_run=True):\n",
    "    # Create datasets\n",
    "    train_dataset = BERTDataset(train, col_name, hf_path)\n",
    "    val_dataset = BERTDataset(val, col_name, hf_path)\n",
    "    test_dataset = BERTDataset(test, col_name, hf_path)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=bert_collate, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=bert_collate)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=bert_collate)\n",
    "\n",
    "    # Initialize model\n",
    "    model = BERTClassifier(hf_path, dropout_rate=dropout_rate)\n",
    "\n",
    "    # Define optimizer and training objective\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define device and move model to CUDA if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Train model\n",
    "    for e in range(1, epochs+1):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        training_loss = 0\n",
    "        \n",
    "        for i, b in enumerate(train_loader):\n",
    "\n",
    "            # Perform forward pass\n",
    "            optimizer.zero_grad()\n",
    "            paragraphs, masks, lbls = [t.to(device) for t in b]\n",
    "            output = model(paragraphs, masks)\n",
    "            loss = criterion(output, lbls)\n",
    "            training_loss += loss\n",
    "            \n",
    "            # Perform backpropagation and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        training_loss = training_loss / len(train_loader)\n",
    "    \n",
    "        # Evaluate model on development data\n",
    "        model.eval()\n",
    "\n",
    "        y_true = list()\n",
    "        y_pred = list()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for b in val_loader:\n",
    "                paragraphs, masks, lbls = [t.to(device) for t in b]\n",
    "                output = model(paragraphs, masks)\n",
    "                max_output = output.argmax(dim=1)\n",
    "                y_true.extend(lbls.tolist())\n",
    "                y_pred.extend(max_output.tolist())\n",
    "                loss += criterion(output, lbls)\n",
    "        val_loss = loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {e}: Training loss {training_loss:.2f}--Val loss {val_loss:.2f}--Accuracy {accuracy_score(y_true, y_pred):.2f}\")\n",
    "\n",
    "    if validation_run == True:\n",
    "        return y_true, y_pred # from validation set\n",
    "\n",
    "    else:\n",
    "        # Evaluate model on test data\n",
    "        model.eval()\n",
    "\n",
    "        y_true = list()\n",
    "        y_pred = list()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for b in test_loader:\n",
    "                paragraphs, masks, lbls = [t.to(device) for t in b]\n",
    "                output = model(paragraphs, masks)\n",
    "                max_output = output.argmax(dim=1)\n",
    "                y_true.extend(lbls.tolist())\n",
    "                y_pred.extend(max_output.tolist())\n",
    "\n",
    "        print('Test accuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "        return model, y_true, y_pred # from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Pneny7NMUB-",
   "metadata": {
    "id": "2Pneny7NMUB-"
   },
   "outputs": [],
   "source": [
    "def get_best_parameters(hf_path, train, val, test, col_name, lrs, dropouts, augs, epochs):\n",
    "    f1_results = []\n",
    "    for lr, dropout, augmented in tqdm(list(product(lrs, dropouts, augs))):\n",
    "        if augmented==True:\n",
    "            y_true, y_pred = bert_finetuning(hf_path, augmented_train, val, test, \n",
    "                                            col_name, lr=lr, epochs=epochs, \n",
    "                                            dropout_rate=dropout, \n",
    "                                            validation_run=True)\n",
    "        else:\n",
    "            y_true, y_pred = bert_finetuning(hf_path, train, val, test, \n",
    "                                            col_name, lr=lr, epochs=epochs, \n",
    "                                            dropout_rate=dropout, \n",
    "                                            validation_run=True)\n",
    "        macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        f1_results.append(({'lr': lr, \n",
    "                            'dropout': dropout, \n",
    "                            'augmented': augmented}, macro_f1))\n",
    "    best_params, best_score = max(f1_results, key = lambda i : i[1])\n",
    "    print(f\"Best score: {best_score}\")\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    return best_params\n",
    "        \n",
    "def print_classification_report_heatmap(actuals, preds):\n",
    "    # Get classification report\n",
    "    print(classification_report(actuals, preds, digits = 4))\n",
    "    \n",
    "    # Get AUROC score\n",
    "    print(f\"ROC AUC score: {roc_auc_score(actuals, preds)}\") #returns macro by default\n",
    "\n",
    "    # Get heatmap\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    process_mat = confusion_matrix(actuals, preds)\n",
    "    sns.heatmap(process_mat.T, square = True, annot=True, fmt = \"d\", ax=ax)\n",
    "    ax.set_xlabel(\"true labels\")\n",
    "    ax.set_ylabel(\"predicted labels\")\n",
    "    plt.show()\n",
    "\n",
    "def find_and_run_best_model(which_model, col_name, train, val, test, lrs, dropouts, augs, epochs):\n",
    "    # Get hf_path (path to right Hugging Face model)\n",
    "    if which_model == 'BERT':\n",
    "        hf_path = 'bert-base-uncased'\n",
    "    else:\n",
    "        hf_path = 'nbroad/ESG-BERT'\n",
    "    \n",
    "    # Find best hyperparameters\n",
    "    best_params = get_best_parameters(hf_path, train, val, test, col_name, \n",
    "                                      lrs, dropouts, augs, epochs)\n",
    "    lr = best_params['lr']\n",
    "    dropout = best_params['dropout']\n",
    "    augmented = best_params['augmented']\n",
    "\n",
    "    # See performance of best model on test data\n",
    "    if augmented == True:\n",
    "        model, y_true, y_pred = bert_finetuning(hf_path, augmented_train, val, test, \n",
    "                                        col_name, lr=lr, epochs=epochs, \n",
    "                                        dropout_rate=dropout,\n",
    "                                        validation_run=False)\n",
    "        path = f'/content/drive/MyDrive/{col_name}-AUG-{which_model}.pth'\n",
    "    else:\n",
    "        model, y_true, y_pred = bert_finetuning(hf_path, train, val, test, \n",
    "                                        col_name, lr=lr, epochs=epochs, \n",
    "                                        dropout_rate=dropout,\n",
    "                                        validation_run=False)\n",
    "        path = f'/content/drive/MyDrive/{col_name}-{which_model}.pth'\n",
    "    print_classification_report_heatmap(y_true, y_pred)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model, path)\n",
    "\n",
    "    return y_pred, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N34-ICx2Qq3k",
   "metadata": {
    "id": "N34-ICx2Qq3k"
   },
   "source": [
    "## Get best models with BERT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ohc-hqFn_ucB",
   "metadata": {
    "id": "ohc-hqFn_ucB"
   },
   "outputs": [],
   "source": [
    "bert_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lh6cqA4g_9-X",
   "metadata": {
    "id": "lh6cqA4g_9-X"
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fvTGNH9A_sVL",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "fvTGNH9A_sVL",
    "outputId": "56f09d31-1c80-4145-f648-04cb1b550df8"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Process_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2],\n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "bert_dict['Process_action'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OdUZAdh8F3-1",
   "metadata": {
    "id": "OdUZAdh8F3-1"
   },
   "source": [
    "### Process augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w-z1p63WF4Sd",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w-z1p63WF4Sd",
    "outputId": "e50d2b23-2de3-4c09-fc1c-187679452ded"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Process_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2],\n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "bert_dict['Process_action_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GMid-oqfAAUI",
   "metadata": {
    "id": "GMid-oqfAAUI"
   },
   "source": [
    "### Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LqErs9G2_se5",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LqErs9G2_se5",
    "outputId": "9eacdfa6-e7f5-4661-839a-53c91ea02aca"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Market_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "bert_dict['Market_action'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wx2YteWkAEUV",
   "metadata": {
    "id": "Wx2YteWkAEUV"
   },
   "source": [
    "### Market augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_KSQIG7_smJ",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_KSQIG7_smJ",
    "outputId": "b58fe3a7-5aec-4f12-bfdf-8e8f40ee8a24"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Market_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "bert_dict['Market_action_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_64yV6jIAHN9",
   "metadata": {
    "id": "_64yV6jIAHN9"
   },
   "source": [
    "### Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4knusg44_suo",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4knusg44_suo",
    "outputId": "d85e364b-4892-4d1c-9c08-7b6ea8d3d234"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Social', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "bert_dict['Social'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ii0eq5IhGQ_5",
   "metadata": {
    "id": "ii0eq5IhGQ_5"
   },
   "source": [
    "### Social augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gPUq3vsFGRKq",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gPUq3vsFGRKq",
    "outputId": "f18cd7d5-86f5-4824-e227-4e6582807e27"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Social', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "bert_dict['Social_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6RrFh1hkAfn1",
   "metadata": {
    "id": "6RrFh1hkAfn1"
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D0lHcgsp_s2e",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0lHcgsp_s2e",
    "outputId": "c303eddd-dcd7-4d35-e744-9f464d33477e"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Environment', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "bert_dict['Environment'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZSiMsAlpGef6",
   "metadata": {
    "id": "ZSiMsAlpGef6"
   },
   "source": [
    "### Environment augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gt16xi9LGerP",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt16xi9LGerP",
    "outputId": "cfdd65b7-4257-4231-8c6a-042ae9432dfb"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('BERT',\n",
    "                                              'Environment', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "bert_dict['Environment_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4u5tRZ5oBsp1",
   "metadata": {
    "id": "4u5tRZ5oBsp1"
   },
   "source": [
    "### Save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QQdrSIEaSgoz",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QQdrSIEaSgoz"
   },
   "outputs": [],
   "source": [
    "# Save dictionary for later\n",
    "with open(\"/content/drive/MyDrive/bert_dict.txt\", \"wb\") as f:\n",
    "    pickle.dump(bert_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_7NziLzeBW9u",
   "metadata": {
    "id": "_7NziLzeBW9u"
   },
   "source": [
    "## Get best models with ESGBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6183a-62b9-4b32-982d-fab2d56e6f12",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cfe6183a-62b9-4b32-982d-fab2d56e6f12"
   },
   "outputs": [],
   "source": [
    "# Note: details on ESG-BERT here: https://huggingface.co/nbroad/ESG-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hI63rCChBLeg",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hI63rCChBLeg"
   },
   "outputs": [],
   "source": [
    "esgbert_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-zIuVQgsBbDL",
   "metadata": {
    "id": "-zIuVQgsBbDL"
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12xlpAU9BaLk",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "12xlpAU9BaLk",
    "outputId": "2b2cb673-b547-40e5-8dee-a86004372eae"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT', \n",
    "                                              'Process_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Process_action'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xx3v1K72GnZK",
   "metadata": {
    "id": "Xx3v1K72GnZK"
   },
   "source": [
    "### Process augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3F3H2ziMGmvc",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3F3H2ziMGmvc",
    "outputId": "d4a346ed-ced0-408c-f309-fc592dd16ee9"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT', \n",
    "                                              'Process_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Process_action_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZJotmWpgBb1i",
   "metadata": {
    "id": "ZJotmWpgBb1i"
   },
   "source": [
    "### Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5IHuYD1WBaDJ",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5IHuYD1WBaDJ",
    "outputId": "0f0ba5c7-05c5-4954-b549-77a2a8d6f27d"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Market_action',\n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Market_action'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dg-tPbn6Bcse",
   "metadata": {
    "id": "Dg-tPbn6Bcse"
   },
   "source": [
    "### Market augmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L7QQ1Wo9BZ78",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "L7QQ1Wo9BZ78",
    "outputId": "49906821-c1ff-4193-c072-b18123c62aad"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Market_action', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Market_action_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A-FKdiX9BdvW",
   "metadata": {
    "id": "A-FKdiX9BdvW"
   },
   "source": [
    "### Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U-4SAgLFBZ2e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "U-4SAgLFBZ2e",
    "outputId": "7ab2e787-bef6-4b37-ea27-8bad47ea003e"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Social', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Social'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oNYnM2TbGyRk",
   "metadata": {
    "id": "oNYnM2TbGyRk"
   },
   "source": [
    "### Social augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EwjP7AJLGycA",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwjP7AJLGycA",
    "outputId": "223a2234-4190-46e2-d1ed-2d3d02eeaeb1"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Social', \n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Social_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTpHHnl8BeS0",
   "metadata": {
    "id": "pTpHHnl8BeS0"
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Qfbme6FBZwt",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6Qfbme6FBZwt",
    "outputId": "53e06660-a2c6-4d5c-c3ed-cc8f7329b5ed"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Environment',\n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[False], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Environment'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KIJlf72gHFDF",
   "metadata": {
    "id": "KIJlf72gHFDF"
   },
   "source": [
    "### Environment augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-ROXVTX1HFQQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-ROXVTX1HFQQ",
    "outputId": "d527532b-59bc-4043-b959-17673b08dd49"
   },
   "outputs": [],
   "source": [
    "y_pred, best_params = find_and_run_best_model('ESG-BERT',\n",
    "                                              'Environment',\n",
    "                                              train, \n",
    "                                              val, \n",
    "                                              test, \n",
    "                                              lrs=[5e-5, 1e-5, 1e-6], \n",
    "                                              dropouts=[0.1, 0.2], \n",
    "                                              augs=[True], \n",
    "                                              epochs=3)\n",
    "esgbert_dict['Environment_AUG'] = {'Preds': y_pred, 'Best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81cz5EBw9R",
   "metadata": {
    "id": "6b81cz5EBw9R"
   },
   "source": [
    "### Save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHcRWR-eBrWE",
   "metadata": {
    "id": "vHcRWR-eBrWE"
   },
   "outputs": [],
   "source": [
    "# Save dictionary for later\n",
    "with open(\"/content/drive/MyDrive/esgbert_dict.txt\", \"wb\") as f:\n",
    "    pickle.dump(esgbert_dict, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "BERT-based models--RECHECKED-626.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
